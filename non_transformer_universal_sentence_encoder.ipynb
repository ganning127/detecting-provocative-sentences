{"cells":[{"cell_type":"markdown","metadata":{"id":"fpRGJV4Ph-cQ"},"source":["## Basic Models (non-transformer-based)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3714,"status":"ok","timestamp":1667502850057,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"KN9pZX5NigfK","outputId":"eafff5c5-0556-4e49-866c-7d0cb4d0465c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: demoji in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"]}],"source":["!pip install demoji"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zLL2J3qTh8bD","executionInfo":{"status":"ok","timestamp":1667502860362,"user_tz":240,"elapsed":10308,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}}},"outputs":[],"source":["import gspread\n","import pandas as pd\n","from tensorflow import keras\n","import numpy as np\n","from google.colab import auth\n","auth.authenticate_user()\n","from google.auth import default\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold, StratifiedKFold\n","import torch\n","\n","creds, _ = default()\n","gc = gspread.authorize(creds)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":2775,"status":"ok","timestamp":1667502863121,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"eWruwsQbiEU0","outputId":"2fb091b8-0afa-4e58-bf33-08dbc2394e68"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                              sentence       final  \\\n","1     * 4 * When those Muslims came to attack Parlia...  oppression   \n","2     His sisters or sisters-in-law begin to force him.        none   \n","3     ‚Äù Entered, broke the Shivling into pieces, and...     culture   \n","4                Muslims should change their instincts.      action   \n","5                   They buy potato, onion, ginger etc.        none   \n","...                                                 ...         ...   \n","6996  More recently, you may have seen the \"Abu Bakr...  oppression   \n","6997  * It is clear from these four examples how wro...        none   \n","6998  In his view, atheist means one who does not be...     culture   \n","6999  üö©  _ * * üö© üïâ üïâ ‚öú   ‚õ≥   ‚öú   - üò¨ Nurul Rahman Ba...      action   \n","7000  * No sir, this problem is not a problem of Kas...        none   \n","\n","0                                                before  \\\n","1     * * When that Muslim When he came to attack 26...   \n","2     So these Muslim friends start visiting the hom...   \n","3     His scattered remains were surely nurturing th...   \n","4     There is a lot of poison in the speech of Musl...   \n","5     There is cold storage for üëâ  üëâ  keeping your o...   \n","...                                                 ...   \n","6996  From the \"Ganga-Jamuni Tehzeeb\", drunken Hindu...   \n","6997  In this way he says that when the world adopts...   \n","6998  The Islamic view of looking at the borders of ...   \n","6999  We should not be üì≤  üì±  begging anyone, we know...   \n","7000       * Will these improve with a surgical strike?   \n","\n","0                                                 after  \n","1     * * Even when those Muslims were going to figh...  \n","2     And how many such girls from Hindu families ar...  \n","3     That property was estimated at two crore dirhams.  \n","4     Muslims have got their desired thing in Pakist...  \n","5     at very cheap prices directly from farmers dur...  \n","...                                                 ...  \n","6996  Like the goats in Pakistan, Hindu girls would ...  \n","6997  * The great prophet Savarkar * In 1952 Savarka...  \n","6998  Islam is not just a religion, in fact Islam is...  \n","6999  ‡•ÇHindu cannot stop our Bangladeshi brothers fr...  \n","7000  * This is purely Islamic Jihad, it will end wi...  \n","\n","[7000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-ee0edc8a-3df7-427b-80d9-b93974e2b323\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>final</th>\n","      <th>before</th>\n","      <th>after</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>* 4 * When those Muslims came to attack Parlia...</td>\n","      <td>oppression</td>\n","      <td>* * When that Muslim When he came to attack 26...</td>\n","      <td>* * Even when those Muslims were going to figh...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>His sisters or sisters-in-law begin to force him.</td>\n","      <td>none</td>\n","      <td>So these Muslim friends start visiting the hom...</td>\n","      <td>And how many such girls from Hindu families ar...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>‚Äù Entered, broke the Shivling into pieces, and...</td>\n","      <td>culture</td>\n","      <td>His scattered remains were surely nurturing th...</td>\n","      <td>That property was estimated at two crore dirhams.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Muslims should change their instincts.</td>\n","      <td>action</td>\n","      <td>There is a lot of poison in the speech of Musl...</td>\n","      <td>Muslims have got their desired thing in Pakist...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>They buy potato, onion, ginger etc.</td>\n","      <td>none</td>\n","      <td>There is cold storage for üëâ  üëâ  keeping your o...</td>\n","      <td>at very cheap prices directly from farmers dur...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6996</th>\n","      <td>More recently, you may have seen the \"Abu Bakr...</td>\n","      <td>oppression</td>\n","      <td>From the \"Ganga-Jamuni Tehzeeb\", drunken Hindu...</td>\n","      <td>Like the goats in Pakistan, Hindu girls would ...</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>* It is clear from these four examples how wro...</td>\n","      <td>none</td>\n","      <td>In this way he says that when the world adopts...</td>\n","      <td>* The great prophet Savarkar * In 1952 Savarka...</td>\n","    </tr>\n","    <tr>\n","      <th>6998</th>\n","      <td>In his view, atheist means one who does not be...</td>\n","      <td>culture</td>\n","      <td>The Islamic view of looking at the borders of ...</td>\n","      <td>Islam is not just a religion, in fact Islam is...</td>\n","    </tr>\n","    <tr>\n","      <th>6999</th>\n","      <td>üö©  _ * * üö© üïâ üïâ ‚öú   ‚õ≥   ‚öú   - üò¨ Nurul Rahman Ba...</td>\n","      <td>action</td>\n","      <td>We should not be üì≤  üì±  begging anyone, we know...</td>\n","      <td>‡•ÇHindu cannot stop our Bangladeshi brothers fr...</td>\n","    </tr>\n","    <tr>\n","      <th>7000</th>\n","      <td>* No sir, this problem is not a problem of Kas...</td>\n","      <td>none</td>\n","      <td>* Will these improve with a surgical strike?</td>\n","      <td>* This is purely Islamic Jihad, it will end wi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7000 rows √ó 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee0edc8a-3df7-427b-80d9-b93974e2b323')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ee0edc8a-3df7-427b-80d9-b93974e2b323 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ee0edc8a-3df7-427b-80d9-b93974e2b323');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["worksheet = gc.open('USE DATASET').worksheet(\"Sheet1\")\n","rows = worksheet.get_all_values()\n","df = pd.DataFrame.from_records(rows)\n","df.columns=df.iloc[0]\n","df = df.drop([0])\n","df = df[['sentence', 'final', 'before', 'after']] # keep only the sentence and class cols\n","df = df.dropna()\n","df = df[(df[\"final\"] != \"\") & (df[\"final\"] != \"Undecided\")]\n","df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1667502863122,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"bhBkC3pFiKPZ","outputId":"5df24024-4be9-4d95-d85a-9012429c2e2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  labels\n","0         Hizbul Mujahideen = Terrorist Organization 6.       0\n","1     * Hindus will get India killed like Pakistan, ...       0\n","2     * * We, the great Akbar's great-grandson Dara ...       0\n","3                     Will sit and corrupt the temples?       0\n","4     Pakistan is a laboratory for terrorism, not a ...       0\n","...                                                 ...     ...\n","6995  The Congress has fielded Rahul Gandhi as a UDF...       0\n","6996  This was the aim of many Muslim invaders to co...       1\n","6997  Methods of his normal behavior have been displ...       0\n","6998  *Like the Hindus of Kerala, no other community...       0\n","6999  3 - Yakub Memon, who lived in the same country...       1\n","\n","[7000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-6b914db1-6aca-4817-8348-a2861bd7a6d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hizbul Mujahideen = Terrorist Organization 6.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>* Hindus will get India killed like Pakistan, ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>* * We, the great Akbar's great-grandson Dara ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Will sit and corrupt the temples?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Pakistan is a laboratory for terrorism, not a ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6995</th>\n","      <td>The Congress has fielded Rahul Gandhi as a UDF...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6996</th>\n","      <td>This was the aim of many Muslim invaders to co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>Methods of his normal behavior have been displ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6998</th>\n","      <td>*Like the Hindus of Kerala, no other community...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6999</th>\n","      <td>3 - Yakub Memon, who lived in the same country...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7000 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b914db1-6aca-4817-8348-a2861bd7a6d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6b914db1-6aca-4817-8348-a2861bd7a6d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6b914db1-6aca-4817-8348-a2861bd7a6d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df = df.sample(frac=1).reset_index(drop=True)\n","replacement = {\n","    'none': 0,\n","    'oppression': 1,\n","    'action': 2,\n","    'culture': 3\n","}\n","\n","df['labels'] = df['final'].map(replacement)\n","df_keep = df[['sentence', 'labels']]\n","df_keep.columns = [\"text\", \"labels\"]\n","df_keep"]},{"cell_type":"markdown","metadata":{"id":"lCIv7os1iM96"},"source":["## Combining Sentences & Oversampling"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1805,"status":"ok","timestamp":1667502864921,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"hhwp9gpGiK0p","outputId":"75fd83f1-4ec2-4465-de94-a4254d2ea73c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  labels\n","0     Hamas = Terrorist Organization 5. Hizbul Mujah...       0\n","1     * Will give 100% government jobs to Christians...       0\n","2     He was so great and generous that even the bes...       0\n","3     * According to Chapter 28, Sai Baba forced a B...       0\n","4     Will never buy this product. Pakistan is a lab...       0\n","...                                                 ...     ...\n","6995  Wayanad has been a stronghold of the Muslim Le...       0\n","6996  \"Gajwa-e-Hind\" means conquering India and esta...       1\n","6997  Islamist politics is active in many names arou...       0\n","6998  *  At the same time, the Muslim share is 30, 2...       0\n","6999  And in the whole #world_dreamed of blood? 3 - ...       1\n","\n","[7000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-1a78d615-7219-4576-b8be-dda557503bae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hamas = Terrorist Organization 5. Hizbul Mujah...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>* Will give 100% government jobs to Christians...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>He was so great and generous that even the bes...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>* According to Chapter 28, Sai Baba forced a B...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Will never buy this product. Pakistan is a lab...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6995</th>\n","      <td>Wayanad has been a stronghold of the Muslim Le...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6996</th>\n","      <td>\"Gajwa-e-Hind\" means conquering India and esta...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>Islamist politics is active in many names arou...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6998</th>\n","      <td>*  At the same time, the Muslim share is 30, 2...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6999</th>\n","      <td>And in the whole #world_dreamed of blood? 3 - ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7000 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a78d615-7219-4576-b8be-dda557503bae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1a78d615-7219-4576-b8be-dda557503bae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1a78d615-7219-4576-b8be-dda557503bae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["combs = []\n","labels = df['labels']\n","\n","for i in range(len(df)):\n","    combs.append(df.loc[i].before + \" \" + df.loc[i].sentence)\n","\n","df_combs = pd.DataFrame(data={\n","    'text': combs,\n","    'labels': labels\n","})\n","df_combs"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1667502864921,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"Qod-g5EXiOv4","outputId":"98a52e27-ffac-4979-a993-529eea2bf909"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  labels\n","0     * Do not try to see communalism with a single ...       1\n","1     Etc., etc., but would never say to improve tha...       0\n","2     In this, he has said that reservation should b...       0\n","3     6 - Islam will enter its bill. Muhammad himsel...       3\n","4     Have made superflops and made such articles an...       3\n","...                                                 ...     ...\n","6995  * Now there is nothing in #India for them, \"We...       0\n","6996  The entire Sindh belonged to the Sindhis seven...       1\n","6997  Mahatma Gandhi used to present himself as a be...       1\n","6998  But if you are a Kashmiri Sunni and a lot of w...       0\n","6999  Today Hindu / Gods and Goddesses are mocked an...       1\n","\n","[7000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-15f2c7ed-e103-4dfa-a113-d5abe2816204\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>* Do not try to see communalism with a single ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Etc., etc., but would never say to improve tha...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In this, he has said that reservation should b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6 - Islam will enter its bill. Muhammad himsel...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Have made superflops and made such articles an...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6995</th>\n","      <td>* Now there is nothing in #India for them, \"We...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6996</th>\n","      <td>The entire Sindh belonged to the Sindhis seven...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6997</th>\n","      <td>Mahatma Gandhi used to present himself as a be...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6998</th>\n","      <td>But if you are a Kashmiri Sunni and a lot of w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6999</th>\n","      <td>Today Hindu / Gods and Goddesses are mocked an...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7000 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15f2c7ed-e103-4dfa-a113-d5abe2816204')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15f2c7ed-e103-4dfa-a113-d5abe2816204 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15f2c7ed-e103-4dfa-a113-d5abe2816204');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["df_combs = df_combs.sample(frac=1).reset_index(drop=True)\n","df_combs.columns = [\"text\", \"labels\"]\n","df_combs"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1667502864922,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"DN3N5mcOiQx0","outputId":"911360d4-c44e-4636-e678-a99a7742126e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    3923\n","1    3923\n","2    3923\n","3    3923\n","Name: labels, dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# Oversampling the dataset\n","c0 = df_combs[df_combs['labels'] == 0]\n","c1 = df_combs[df_combs['labels'] == 1]\n","c2 = df_combs[df_combs['labels'] == 2]\n","c3 = df_combs[df_combs['labels'] == 3]\n","\n","c1_over = c1.sample(len(c0), replace=True)\n","c2_over = c2.sample(len(c0), replace=True)\n","c3_over = c3.sample(len(c0), replace=True)\n","\n","df_oversample = pd.concat([c0, c1_over, c2_over, c3_over], axis=0)\n","df_oversample['labels'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"uQ4q6W1jipZO"},"source":["## Dataset Cleaning"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1667502866265,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"ZUHRLQ3MiR8O","outputId":"f336c885-65a8-479f-b779-d501337a05f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["import re\n","import nltk\n","import demoji\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","stemmer = WordNetLemmatizer()\n","\n","\n","class Cleaner:\n","  def replace_emoji_and_dup(self, text):\n","    '''\n","    function takes in string `text` parameter and removes all duplicate characters in a row that are greater than 2 \n","    -replaces the emojis with their descriptions\n","    '''\n","    tracker = {}\n","    final = []\n","\n","    # check if the past two characters were that same char\n","\n","    for i in range(len(text)):\n","      if i < 2:\n","        final.append(text[i])\n","        continue\n","      if (text[i-1] == text[i]) and (text[i-2] == text[i]):\n","        pass\n","      else:\n","        final.append(text[i])\n","\n","    final = \"\".join(final)\n","    return demoji.replace_with_desc(final)\n","\n","  def replace_url(self, text):\n","    '''\n","    function takes a `string` parameter text and replaces all URLS with `_URL` \n","    '''\n","    return re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", ' _URL', text)\n","\n","\n","  def final_clean(self, text):\n","    text = re.sub(r'\\W', ' ', str(text))\n","    \n","    # remove all single characters\n","    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n","    \n","    # Remove single characters from the start\n","    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n","    \n","    # Substituting multiple spaces with single space\n","    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n","    \n","    # Removing prefixed 'b'\n","    text = re.sub(r'^b\\s+', '', text)\n","    \n","    # Converting to Lowercase\n","    text = text.lower()\n","    \n","    # Lemmatization\n","    text = text.split()\n","\n","    text = [stemmer.lemmatize(word) for word in text]\n","    text = ' '.join(text)\n","    \n","    return text\n","\n","  def clean_text(self, text):\n","    '''\n","    MASTER FUNCTION\n","    '''\n","    # remove emojis and duplicate chars\n","    clean1 = self.replace_emoji_and_dup(str(text))\n","\n","    # replace links with _URL\n","    clean2 = self.replace_url(clean1)\n","\n","    final = self.final_clean(clean2)\n","\n","    return final\n","\n","Cleaner = Cleaner()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":29110,"status":"ok","timestamp":1667502895373,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"3sa7zKupid6D","outputId":"8e4739aa-11ea-4340-ef43-536b2aa1076b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  labels\n","1     etc etc but would never say to improve that bo...       0\n","2     in this he ha said that reservation should be ...       0\n","5     the objection and the plight of hindu coming f...       0\n","6     shushing face ‡§ú ajib is ironic ‡§Ø‡§π for some of ...       0\n","7     he wa accompanied by his sister wife and nephe...       0\n","...                                                 ...     ...\n","4500  and towards india it is also spreading it fun ...       3\n","3569  hindu muslim sikh christian sabal 16 what is t...       3\n","6539  the entire hindu society will have to get orga...       3\n","4081  there are son but to blunt their anger we star...       3\n","550   every muslim should share now read this quran ...       3\n","\n","[15692 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-af5f8f57-3df0-459a-8beb-a469d75283a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>etc etc but would never say to improve that bo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>in this he ha said that reservation should be ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>the objection and the plight of hindu coming f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>shushing face ‡§ú ajib is ironic ‡§Ø‡§π for some of ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>he wa accompanied by his sister wife and nephe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4500</th>\n","      <td>and towards india it is also spreading it fun ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3569</th>\n","      <td>hindu muslim sikh christian sabal 16 what is t...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6539</th>\n","      <td>the entire hindu society will have to get orga...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4081</th>\n","      <td>there are son but to blunt their anger we star...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>550</th>\n","      <td>every muslim should share now read this quran ...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15692 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5f8f57-3df0-459a-8beb-a469d75283a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-af5f8f57-3df0-459a-8beb-a469d75283a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-af5f8f57-3df0-459a-8beb-a469d75283a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["def prepreocess_text(text):\n","    return Cleaner.clean_text(text)\n","\n","df_oversample['text'] = df_oversample['text'].apply(prepreocess_text)\n","df_oversample"]},{"cell_type":"code","source":["#@title Load the Universal Sentence Encoder's TF Hub module\n","from absl import logging\n","\n","import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","import seaborn as sns\n","\n","module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n","modelHub = hub.load(module_url)\n","print (\"module %s loaded\" % module_url)\n","def embed(input):\n","  return modelHub(input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0Upv37-2WN1","executionInfo":{"status":"ok","timestamp":1667502978299,"user_tz":240,"elapsed":4589,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"f879e90d-2f3a-49ab-bf0a-666d3e719e84"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"]}]},{"cell_type":"code","source":["#@title Compute a representation for each message, showing various lengths supported.\n","word = \"Elephant\"\n","sentence = \"I am a sentence for which I would like to get its embedding.\"\n","paragraph = (\n","    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n","    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n","    \"the more 'diluted' the embedding will be.\")\n","messages = [sentence]\n","\n","# Reduce logging output.\n","logging.set_verbosity(logging.ERROR)\n","\n","message_embeddings = embed(df_oversample['text'])"],"metadata":{"id":"D65gqAlQ2oEl","executionInfo":{"status":"ok","timestamp":1667502916194,"user_tz":240,"elapsed":9577,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["len(np.array(message_embeddings))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMyhxV6233rL","executionInfo":{"status":"ok","timestamp":1667502916196,"user_tz":240,"elapsed":11,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"39850808-38c0-4b5f-f0d2-6f9cb3d5b7a4"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15692"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["df_oversample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Zxs2yQ_24ObN","executionInfo":{"status":"ok","timestamp":1667502916196,"user_tz":240,"elapsed":8,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"d7f73153-0f29-4da6-921e-1874f0516de2"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  labels\n","1     etc etc but would never say to improve that bo...       0\n","2     in this he ha said that reservation should be ...       0\n","5     the objection and the plight of hindu coming f...       0\n","6     shushing face ‡§ú ajib is ironic ‡§Ø‡§π for some of ...       0\n","7     he wa accompanied by his sister wife and nephe...       0\n","...                                                 ...     ...\n","4500  and towards india it is also spreading it fun ...       3\n","3569  hindu muslim sikh christian sabal 16 what is t...       3\n","6539  the entire hindu society will have to get orga...       3\n","4081  there are son but to blunt their anger we star...       3\n","550   every muslim should share now read this quran ...       3\n","\n","[15692 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-4dd923b6-7cca-4f09-b617-18aa96170853\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>etc etc but would never say to improve that bo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>in this he ha said that reservation should be ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>the objection and the plight of hindu coming f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>shushing face ‡§ú ajib is ironic ‡§Ø‡§π for some of ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>he wa accompanied by his sister wife and nephe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4500</th>\n","      <td>and towards india it is also spreading it fun ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3569</th>\n","      <td>hindu muslim sikh christian sabal 16 what is t...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6539</th>\n","      <td>the entire hindu society will have to get orga...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4081</th>\n","      <td>there are son but to blunt their anger we star...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>550</th>\n","      <td>every muslim should share now read this quran ...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15692 rows √ó 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dd923b6-7cca-4f09-b617-18aa96170853')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4dd923b6-7cca-4f09-b617-18aa96170853 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4dd923b6-7cca-4f09-b617-18aa96170853');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas  as pd\n","from io import StringIO\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import MinMaxScaler #fixed import\n"],"metadata":{"id":"HbvbXMfq27fQ","executionInfo":{"status":"ok","timestamp":1667502930908,"user_tz":240,"elapsed":366,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# All the models that we are going to try\n","models = [\n","    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n","    SVC(kernel='rbf'),#SVM\n","    MultinomialNB(),#Naive Bayes classifier for multinomial models\n","    LogisticRegression(random_state=0),\n","]\n","\n","def get_avg(lst):\n","    return sum(lst) / len(lst)\n","\n","for model in models:\n","    model_name = model.__class__.__name__\n","    print(f'----------------------Model: {model_name}----------------------')\n","    none_precisions = []\n","    none_recalls = []\n","    none_f1s = []\n","\n","    action_precisions = []\n","    action_recalls = []\n","    action_f1s = []\n","    \n","    oppression_precisions = []\n","    oppression_recalls = []\n","    oppression_f1s = []\n","\n","    culture_precisions = []\n","    culture_recalls = []\n","    culture_f1s = []\n","\n","    var = 0\n","    n=10\n","    skf = StratifiedKFold(n_splits=n, random_state=1337, shuffle=True)\n","    confusions = []\n","\n","\n","    features = embed(df_oversample['text']).numpy()\n","\n","\n","    labels = df_oversample['labels']\n","\n","\n","    for i, x in enumerate(skf.split(df_oversample['text'], df_oversample['labels'])):\n","        df_train = df_oversample.iloc[x[0].tolist()]\n","        df_test = df_oversample.iloc[x[1].tolist()]\n","\n","        axis=1\n","        features_train = features[x[0]]\n","        features_test = features[x[1]]\n","\n","        \n","\n","        X_train = features_train\n","        y_train = df_train['labels']\n","        X_test = features_test\n","        y_test = df_test['labels']\n","        \n","\n","        print(f'{i}th split...')\n","        print(df_train.shape)\n","        print(df_test.shape)\n","\n","\n","\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        report = metrics.classification_report(y_test, y_pred, target_names = ['none', 'oppression', 'action', 'culture'], output_dict=True)\n","\n","        none_precisions.append(report['none']['precision'])\n","        none_recalls.append(report['none']['recall'])\n","        none_f1s.append(report['none']['f1-score'])\n","\n","        action_precisions.append(report['action']['precision'])\n","        action_recalls.append(report['action']['recall'])\n","        action_f1s.append(report['action']['f1-score'])\n","\n","        oppression_precisions.append(report['oppression']['precision'])\n","        oppression_recalls.append(report['oppression']['recall'])\n","        oppression_f1s.append(report['oppression']['f1-score'])\n","\n","        culture_precisions.append(report['culture']['precision'])\n","        culture_recalls.append(report['culture']['recall'])\n","        culture_f1s.append(report['culture']['f1-score'])\n","        if i == 9:\n","            break\n","\n","    print(\"none_precision:\", get_avg(none_precisions))\n","    print(\"none_recalls:\", get_avg(none_recalls))\n","    print(\"none_f1s:\", get_avg(none_f1s))\n","\n","    print(\"action_precisions:\", get_avg(action_precisions))\n","    print(\"action_recalls:\", get_avg(action_recalls))\n","    print(\"action_f1s:\", get_avg(action_f1s))\n","\n","    print(\"oppression_precisions:\", get_avg(oppression_precisions))\n","    print(\"oppression_recalls:\", get_avg(oppression_recalls))\n","    print(\"oppression_f1s:\", get_avg(oppression_f1s))\n","    \n","    print(\"culture_precisions:\", get_avg(culture_precisions))\n","    print(\"culture_recalls:\", get_avg(culture_recalls))\n","    print(\"culture_f1s:\", get_avg(culture_f1s))\n","\n","\n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"08osFVjZ3IYX","executionInfo":{"status":"error","timestamp":1667503671194,"user_tz":240,"elapsed":600486,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"7f29645a-fe28-45db-b174-f62bc80cd701"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------Model: RandomForestClassifier----------------------\n","0th split...\n","(14122, 2)\n","(1570, 2)\n","1th split...\n","(14122, 2)\n","(1570, 2)\n","2th split...\n","(14123, 2)\n","(1569, 2)\n","3th split...\n","(14123, 2)\n","(1569, 2)\n","4th split...\n","(14123, 2)\n","(1569, 2)\n","5th split...\n","(14123, 2)\n","(1569, 2)\n","6th split...\n","(14123, 2)\n","(1569, 2)\n","7th split...\n","(14123, 2)\n","(1569, 2)\n","8th split...\n","(14123, 2)\n","(1569, 2)\n","9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.5272694437714727\n","none_recalls: 0.39816884769174843\n","none_f1s: 0.4534827923705098\n","action_precisions: 0.571725283715552\n","action_recalls: 0.6171599937684997\n","action_f1s: 0.5932850644590781\n","oppression_precisions: 0.6000683341410558\n","oppression_recalls: 0.555708313859895\n","oppression_f1s: 0.5767384552676533\n","culture_precisions: 0.49433507879505606\n","culture_recalls: 0.612274108116529\n","culture_f1s: 0.5467537416978621\n","----------------------Model: SVC----------------------\n","0th split...\n","(14122, 2)\n","(1570, 2)\n","1th split...\n","(14122, 2)\n","(1570, 2)\n","2th split...\n","(14123, 2)\n","(1569, 2)\n","3th split...\n","(14123, 2)\n","(1569, 2)\n","4th split...\n","(14123, 2)\n","(1569, 2)\n","5th split...\n","(14123, 2)\n","(1569, 2)\n","6th split...\n","(14123, 2)\n","(1569, 2)\n","7th split...\n","(14123, 2)\n","(1569, 2)\n","8th split...\n","(14123, 2)\n","(1569, 2)\n","9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.832548323581505\n","none_recalls: 0.6887514929635976\n","none_f1s: 0.7536227064937402\n","action_precisions: 0.9223923557341788\n","action_recalls: 0.9928642831178273\n","action_f1s: 0.9563100951830608\n","oppression_precisions: 0.8376168894964945\n","oppression_recalls: 0.8559809419951186\n","oppression_f1s: 0.8464960214195502\n","culture_precisions: 0.8440450297386279\n","culture_recalls: 0.9059335566287585\n","culture_f1s: 0.8737881591796887\n","----------------------Model: MultinomialNB----------------------\n","0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-81b267e1282d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"]}]},{"cell_type":"code","source":["# All the models that we are going to try\n","models = [\n","    # RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n","    # SVC(kernel='rbf'),#SVM\n","    MultinomialNB(),#Naive Bayes classifier for multinomial models\n","    LogisticRegression(random_state=0),\n","]\n","\n","def get_avg(lst):\n","    return sum(lst) / len(lst)\n","\n","for model in models:\n","    model_name = model.__class__.__name__\n","    print(f'----------------------Model: {model_name}----------------------')\n","    none_precisions = []\n","    none_recalls = []\n","    none_f1s = []\n","\n","    action_precisions = []\n","    action_recalls = []\n","    action_f1s = []\n","    \n","    oppression_precisions = []\n","    oppression_recalls = []\n","    oppression_f1s = []\n","\n","    culture_precisions = []\n","    culture_recalls = []\n","    culture_f1s = []\n","\n","    var = 0\n","    n=10\n","    skf = StratifiedKFold(n_splits=n, random_state=1337, shuffle=True)\n","    confusions = []\n","\n","\n","    features = embed(df_oversample['text']).numpy()\n","    scaler = MinMaxScaler()\n","    features = scaler.fit_transform(features)\n","\n","\n","    labels = df_oversample['labels']\n","\n","\n","    for i, x in enumerate(skf.split(df_oversample['text'], df_oversample['labels'])):\n","        df_train = df_oversample.iloc[x[0].tolist()]\n","        df_test = df_oversample.iloc[x[1].tolist()]\n","\n","        axis=1\n","        features_train = features[x[0]]\n","        features_test = features[x[1]]\n","\n","        \n","\n","        X_train = features_train\n","        y_train = df_train['labels']\n","        X_test = features_test\n","        y_test = df_test['labels']\n","        \n","\n","        print(f'{i}th split...')\n","        print(df_train.shape)\n","        print(df_test.shape)\n","\n","\n","\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        report = metrics.classification_report(y_test, y_pred, target_names = ['none', 'oppression', 'action', 'culture'], output_dict=True)\n","\n","        none_precisions.append(report['none']['precision'])\n","        none_recalls.append(report['none']['recall'])\n","        none_f1s.append(report['none']['f1-score'])\n","\n","        action_precisions.append(report['action']['precision'])\n","        action_recalls.append(report['action']['recall'])\n","        action_f1s.append(report['action']['f1-score'])\n","\n","        oppression_precisions.append(report['oppression']['precision'])\n","        oppression_recalls.append(report['oppression']['recall'])\n","        oppression_f1s.append(report['oppression']['f1-score'])\n","\n","        culture_precisions.append(report['culture']['precision'])\n","        culture_recalls.append(report['culture']['recall'])\n","        culture_f1s.append(report['culture']['f1-score'])\n","        if i == 9:\n","            break\n","\n","    print(\"none_precision:\", get_avg(none_precisions))\n","    print(\"none_recalls:\", get_avg(none_recalls))\n","    print(\"none_f1s:\", get_avg(none_f1s))\n","\n","    print(\"action_precisions:\", get_avg(action_precisions))\n","    print(\"action_recalls:\", get_avg(action_recalls))\n","    print(\"action_f1s:\", get_avg(action_f1s))\n","\n","    print(\"oppression_precisions:\", get_avg(oppression_precisions))\n","    print(\"oppression_recalls:\", get_avg(oppression_recalls))\n","    print(\"oppression_f1s:\", get_avg(oppression_f1s))\n","    \n","    print(\"culture_precisions:\", get_avg(culture_precisions))\n","    print(\"culture_recalls:\", get_avg(culture_recalls))\n","    print(\"culture_f1s:\", get_avg(culture_f1s))\n","\n","\n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0n8dpZH92Xv","executionInfo":{"status":"ok","timestamp":1667503855927,"user_tz":240,"elapsed":55957,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"6ff16eb2-bf4d-4ad9-afa7-8a87f21bea1e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------Model: MultinomialNB----------------------\n","0th split...\n","(14122, 2)\n","(1570, 2)\n","1th split...\n","(14122, 2)\n","(1570, 2)\n","2th split...\n","(14123, 2)\n","(1569, 2)\n","3th split...\n","(14123, 2)\n","(1569, 2)\n","4th split...\n","(14123, 2)\n","(1569, 2)\n","5th split...\n","(14123, 2)\n","(1569, 2)\n","6th split...\n","(14123, 2)\n","(1569, 2)\n","7th split...\n","(14123, 2)\n","(1569, 2)\n","8th split...\n","(14123, 2)\n","(1569, 2)\n","9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.507412941501508\n","none_recalls: 0.4973172093264787\n","none_f1s: 0.502139330394911\n","action_precisions: 0.5624969148462153\n","action_recalls: 0.45220698966609546\n","action_f1s: 0.5010153789562093\n","oppression_precisions: 0.5726632204648519\n","oppression_recalls: 0.5065008827958666\n","oppression_f1s: 0.5373053874789291\n","culture_precisions: 0.4610305431818973\n","culture_recalls: 0.613301007425871\n","culture_f1s: 0.5262476853774649\n","----------------------Model: LogisticRegression----------------------\n","0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["1th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["2th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["3th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["4th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["5th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["6th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["7th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["8th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.5724494104407564\n","none_recalls: 0.5077809368022018\n","none_f1s: 0.5380240593243094\n","action_precisions: 0.6603329723372608\n","action_recalls: 0.7280125408942202\n","action_f1s: 0.6923633753894347\n","oppression_precisions: 0.6504282802286683\n","oppression_recalls: 0.6436373786155684\n","oppression_f1s: 0.6466801494178893\n","culture_precisions: 0.6010323802714473\n","culture_recalls: 0.6127849613127693\n","culture_f1s: 0.6067248717320018\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]}]},{"cell_type":"markdown","source":["### --- Archive ---"],"metadata":{"id":"p6UjQP7-2TZi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7k8k2C_zI4zF"},"outputs":[],"source":["embeddings_index = {}\n","f = open('glove.6B.100d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnywiIlWHJYy","executionInfo":{"status":"ok","timestamp":1666553428318,"user_tz":240,"elapsed":348,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"220e6e38-ac4a-49ea-b288-8e0036aa0a34"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n","       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n","       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n","       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n","        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n","        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n","       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n","        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n","        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n","       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n","        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n","       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n","        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n","       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n","       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n","        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n","       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"]},"metadata":{},"execution_count":51}],"source":["embeddings_index['king']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"3YcBJ_5BQA6r","executionInfo":{"status":"error","timestamp":1666553223760,"user_tz":240,"elapsed":175,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"}},"outputId":"6c38b7bf-273b-45ec-b9ac-c07ab2772b35"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-3ea5e5f0cf0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'woman'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'king'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"word 'woman' not in vocabulary\""]}],"source":["result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZswjaZtDrq9G"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas  as pd\n","from io import StringIO\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import MinMaxScaler #fixed import\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jBcdrHu6Hif","outputId":"e72a8dff-5f93-4a9a-b073-92759e026300"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------Model: RandomForestClassifier----------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["1th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["2th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["3th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["4th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["5th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["6th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["7th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["8th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.375666305884105\n","none_recalls: 0.26714960793477693\n","none_f1s: 0.31198946828421986\n","action_precisions: 0.3629776020250902\n","action_recalls: 0.5980176039881602\n","action_f1s: 0.45139069256529635\n","oppression_precisions: 0.3381298459468766\n","oppression_recalls: 0.4266993820428935\n","oppression_f1s: 0.3769554691599\n","culture_precisions: 0.404565555757356\n","culture_recalls: 0.15242444305966663\n","culture_f1s: 0.2210025588308313\n","----------------------Model: MultinomialNB----------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["1th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["2th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["3th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["4th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["5th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["6th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["7th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["8th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["9th split...\n","(14123, 2)\n","(1569, 2)\n","none_precision: 0.28080976162860927\n","none_recalls: 0.4290056862439632\n","none_f1s: 0.3393596764019633\n","action_precisions: 0.30692990104235024\n","action_recalls: 0.506511917744197\n","action_f1s: 0.3821207990008501\n","oppression_precisions: 0.33744858330436367\n","oppression_recalls: 0.2158877291374565\n","oppression_f1s: 0.26282210182134425\n","culture_precisions: 0.35045431912879765\n","culture_recalls: 0.06322376278755777\n","culture_f1s: 0.1068855559374701\n","----------------------Model: LogisticRegression----------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["1th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["2th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["3th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["4th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["5th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["6th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["7th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["8th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["9th split...\n","(14123, 2)\n","(1569, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"name":"stdout","output_type":"stream","text":["none_precision: 0.28168089296784843\n","none_recalls: 0.2910837617489744\n","none_f1s: 0.28569607455444246\n","action_precisions: 0.3064842388134462\n","action_recalls: 0.49554447733291784\n","action_f1s: 0.3784948705527647\n","oppression_precisions: 0.3305471697989997\n","oppression_recalls: 0.3392720828789531\n","oppression_f1s: 0.3341603344310407\n","culture_precisions: 0.2859288848450718\n","culture_recalls: 0.09278574025029859\n","culture_f1s: 0.13966141012227187\n","----------------------Model: SVC----------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["0th split...\n","(14122, 2)\n","(1570, 2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["1th split...\n","(14122, 2)\n","(1570, 2)\n"]}],"source":["# All the models that we are going to try\n","models = [\n","    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n","    \n","    MultinomialNB(),#Naive Bayes classifier for multinomial models\n","    LogisticRegression(random_state=0),\n","    SVC(kernel='rbf'),#SVM\n","]\n","\n","def get_avg(lst):\n","    return sum(lst) / len(lst)\n","\n","for model in models:\n","    model_name = model.__class__.__name__\n","    print(f'----------------------Model: {model_name}----------------------')\n","    none_precisions = []\n","    none_recalls = []\n","    none_f1s = []\n","\n","    action_precisions = []\n","    action_recalls = []\n","    action_f1s = []\n","    \n","    oppression_precisions = []\n","    oppression_recalls = []\n","    oppression_f1s = []\n","\n","    culture_precisions = []\n","    culture_recalls = []\n","    culture_f1s = []\n","\n","    var = 0\n","    n=10\n","    skf = StratifiedKFold(n_splits=n, random_state=1337, shuffle=True)\n","    confusions = []\n","\n","\n","\n","    labels = df_oversample['labels']\n","\n","\n","    for i, x in enumerate(skf.split(df_oversample['text'], df_oversample['labels'])):\n","        df_train = df_oversample.iloc[x[0].tolist()]\n","        df_test = df_oversample.iloc[x[1].tolist()]\n","\n","        axis=1\n","        \n","\n","        X_train = df_train['text']\n","        y_train = df_train['labels']\n","        X_test = df_test['text']\n","        y_test = df_test['labels']\n","        \n","\n","\n","        X_train_vect = np.array([np.array([word2vec.wv[i] for i in ls if i in words])\n","                            for ls in X_train])\n","        X_test_vect = np.array([np.array([word2vec.wv[i] for i in ls if i in words])\n","                            for ls in X_test])\n","        \n","        X_train_vect_avg = []\n","        for v in X_train_vect:\n","            if v.size:\n","                X_train_vect_avg.append(v.mean(axis=0))\n","            else:\n","                X_train_vect_avg.append(np.zeros(100, dtype=float))\n","                \n","        X_test_vect_avg = []\n","        for v in X_test_vect:\n","            if v.size:\n","                X_test_vect_avg.append(v.mean(axis=0))\n","            else:\n","                X_test_vect_avg.append(np.zeros(100, dtype=float))\n","                \n","\n","        print(f'{i}th split...')\n","        print(df_train.shape)\n","        print(df_test.shape)\n","\n","\n","        scaler = MinMaxScaler()\n","        X_train_vect_avg = scaler.fit_transform(X_train_vect_avg)\n","        X_test_vect_avg = scaler.transform(X_test_vect_avg)\n","\n","        model.fit(X_train_vect_avg, y_train)\n","        y_pred = model.predict(X_test_vect_avg)\n","\n","        report = metrics.classification_report(y_test, y_pred, target_names = ['none', 'oppression', 'action', 'culture'], output_dict=True)\n","\n","        none_precisions.append(report['none']['precision'])\n","        none_recalls.append(report['none']['recall'])\n","        none_f1s.append(report['none']['f1-score'])\n","\n","        action_precisions.append(report['action']['precision'])\n","        action_recalls.append(report['action']['recall'])\n","        action_f1s.append(report['action']['f1-score'])\n","\n","        oppression_precisions.append(report['oppression']['precision'])\n","        oppression_recalls.append(report['oppression']['recall'])\n","        oppression_f1s.append(report['oppression']['f1-score'])\n","\n","        culture_precisions.append(report['culture']['precision'])\n","        culture_recalls.append(report['culture']['recall'])\n","        culture_f1s.append(report['culture']['f1-score'])\n","        if i == 9:\n","            break\n","\n","    print(\"none_precision:\", get_avg(none_precisions))\n","    print(\"none_recalls:\", get_avg(none_recalls))\n","    print(\"none_f1s:\", get_avg(none_f1s))\n","\n","    print(\"action_precisions:\", get_avg(action_precisions))\n","    print(\"action_recalls:\", get_avg(action_recalls))\n","    print(\"action_f1s:\", get_avg(action_f1s))\n","\n","    print(\"oppression_precisions:\", get_avg(oppression_precisions))\n","    print(\"oppression_recalls:\", get_avg(oppression_recalls))\n","    print(\"oppression_f1s:\", get_avg(oppression_f1s))\n","    \n","    print(\"culture_precisions:\", get_avg(culture_precisions))\n","    print(\"culture_recalls:\", get_avg(culture_recalls))\n","    print(\"culture_f1s:\", get_avg(culture_f1s))\n","\n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208997,"status":"ok","timestamp":1666546213806,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"wjtTbkjXqT5q","outputId":"6fd9cc01-cae0-437e-83a4-cfff894bc95a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model... RandomForestClassifier\n","fold 0\n","fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n","fold 6\n","fold 7\n","fold 8\n","fold 9\n","Model... LinearSVC\n","fold 0\n","fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n","fold 6\n","fold 7\n","fold 8\n","fold 9\n","Model... MultinomialNB\n","fold 0\n","fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n","fold 6\n","fold 7\n","fold 8\n","fold 9\n","Model... LogisticRegression\n","fold 0\n","fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n","fold 6\n","fold 7\n","fold 8\n","fold 9\n"]}],"source":["# Need to modify this code so that it will do 10 folds of when testing each model\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","models = [\n","    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n","    SVC(kernel='poly'),#SVM\n","    MultinomialNB(),#Naive Bayes classifier for multinomial models\n","    LogisticRegression(random_state=0),\n","]\n","CV = 10\n","cv_df = pd.DataFrame(index=range(CV * len(models)))\n","entries = []\n","for model in models:\n","    model_name = model.__class__.__name__\n","    print(\"Model...\", model_name)\n","    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n","    for fold_idx, accuracy in enumerate(accuracies):\n","        print(\"fold\", fold_idx)\n","        entries.append((model_name, fold_idx, accuracy))\n","cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1666546230438,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"V0sNfZu7ucD4","outputId":"91fb5937-13f2-4590-85ba-68a9118b0f20"},"outputs":[{"data":{"text/plain":["model_name\n","LinearSVC                 0.608857\n","LogisticRegression        0.631429\n","MultinomialNB             0.608000\n","RandomForestClassifier    0.560429\n","Name: accuracy, dtype: float64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Check the accuracy\n","cv_df.groupby('model_name').accuracy.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143666,"status":"ok","timestamp":1666547095811,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"tvmIhqiswW5d","outputId":"9edc2e7b-7e83-4704-9aa7-bb68fdf4709d"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.83      0.83      1245\n","           1       0.90      0.88      0.89      1320\n","           2       0.97      1.00      0.98      1308\n","           3       0.93      0.91      0.92      1306\n","\n","    accuracy                           0.91      5179\n","   macro avg       0.90      0.90      0.90      5179\n","weighted avg       0.91      0.91      0.91      5179\n","\n"]}],"source":["model = RandomForestClassifier()\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=0)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(metrics.classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"elapsed":986,"status":"error","timestamp":1666547652415,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"5Xkr6qDd8Eyf","outputId":"937d8997-b32e-4b3b-e1e9-1c5a611b112c"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-7632e05e63d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oppression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'culture'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1-score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1570, 5179]"]}],"source":["report = metrics.classification_report(y_test, y_pred, target_names = ['none', 'oppression', 'action', 'culture'], output_dict=True)\n","\n","report['none']['f1-score']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1665587590914,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"1Q2e9NpTwV0u","outputId":"04f68ca5-8269-4209-800d-e42eb8aea754"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.95      0.73      1309\n","           1       0.62      0.24      0.35       487\n","           2       0.00      0.00      0.00       141\n","           3       0.64      0.04      0.08       373\n","\n","    accuracy                           0.60      2310\n","   macro avg       0.46      0.31      0.29      2310\n","weighted avg       0.57      0.60      0.50      2310\n","\n"]}],"source":["model = MultinomialNB()\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=0)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(metrics.classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24667,"status":"ok","timestamp":1665587590787,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"DGT__iG1wT7H","outputId":"fccc5596-5563-4948-8dc1-50f63be133a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.89      0.75      1309\n","           1       0.55      0.38      0.45       487\n","           2       0.17      0.01      0.01       141\n","           3       0.51      0.19      0.28       373\n","\n","    accuracy                           0.62      2310\n","   macro avg       0.47      0.37      0.37      2310\n","weighted avg       0.57      0.62      0.56      2310\n","\n"]}],"source":["model = LogisticRegression()\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=0)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(metrics.classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676,"status":"ok","timestamp":1665587543231,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"XBzzBdWtsTxD","outputId":"2077f1d5-2ccf-44a3-fc32-213b01a4a605"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.68      0.78      0.72      1309\n","           1       0.49      0.49      0.49       487\n","           2       0.23      0.08      0.12       141\n","           3       0.42      0.30      0.35       373\n","\n","    accuracy                           0.60      2310\n","   macro avg       0.45      0.41      0.42      2310\n","weighted avg       0.57      0.60      0.58      2310\n","\n"]}],"source":["model = LinearSVC()\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=0)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(metrics.classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNh6OEdrvVEb"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyMQA+EZ4q6LyEH/Y51ZNZfW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}